{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7dc32e5-9392-4c05-b73d-6452f2e1966e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once the data is loaded into the SQL database, we can create queries for specific visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b52e114-6f4b-4d94-a109-0901028908f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- Select the relevant columns from the table\n",
    "SELECT \n",
    "  date,\n",
    "  precipitation,\n",
    "  snow,\n",
    "  snow_on_ground\n",
    "FROM snow_data_db.observations\n",
    "ORDER BY date ASC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e71c9f6-ae1a-46be-9e54-41af3badce7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- Let's only focus on the 'snow' column and let's exclude 2024 since that year is not yet complete.\n",
    "\n",
    "SELECT \n",
    "  date,\n",
    "  snow AS snowfall_cm\n",
    "FROM snow_data_db.observations\n",
    "-- WHERE date BETWEEN '1956-01-01' AND '2023-12-31'\n",
    "WHERE date < '2024'\n",
    "ORDER BY date;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33fc101f-ad65-4abe-9b35-8dec3c3edf00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We see that the snow accumulation for 1872 and 1873 seem a bit off compared to the line trend. Let's start at 1874.\n",
    "<br>Let's also separate the date into year, month, day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9179d4a-1143-405f-9049-413fffd9c80d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Switching back to Python, let's apply the changes and save the query as a separate table in the Hive Metastore\n",
    "\n",
    "df = spark.sql(\n",
    "    \"\"\"\n",
    "WITH cte1 AS (\n",
    "  SELECT\n",
    "    date,\n",
    "    EXTRACT(year FROM date) AS year,\n",
    "    EXTRACT(month FROM date) AS month_num,\n",
    "    date_format(date, 'MMMM') AS month,\n",
    "    EXTRACT(day FROM date) AS day,\n",
    "    date_format(date, 'EEEE') AS weekday,\n",
    "    snow AS snowfall\n",
    "  FROM snow_data_db.observations\n",
    "  WHERE date BETWEEN '1874-01-01' AND '2023-12-31'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  date,\n",
    "  year,\n",
    "  month,\n",
    "  day,\n",
    "  weekday,\n",
    "  snowfall\n",
    "FROM cte1\n",
    "ORDER BY date ASC;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\n",
    "    \"snow_data_db.snowfall_full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4b939f-b3e0-480d-9cc9-9476bf5a7c95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a shorter table for the last 100 years\n",
    "\n",
    "df = spark.sql(\n",
    "    \"\"\"\n",
    "WITH cte1 AS (\n",
    "  SELECT\n",
    "    date,\n",
    "    EXTRACT(year FROM date) AS year,\n",
    "    EXTRACT(month FROM date) AS month_num,\n",
    "    date_format(date, 'MMMM') AS month,\n",
    "    EXTRACT(day FROM date) AS day,\n",
    "    date_format(date, 'EEEE') AS weekday,\n",
    "    snow AS snowfall\n",
    "  FROM snow_data_db.observations\n",
    "  WHERE date BETWEEN '1923-01-01' AND '2023-12-31'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  date,\n",
    "  year,\n",
    "  month,\n",
    "  day,\n",
    "  weekday,\n",
    "  snowfall\n",
    "FROM cte1\n",
    "ORDER BY date ASC;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\n",
    "    \"snow_data_db.snowfall\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "f2645fac-8c10-4ed0-a008-38423c8194e6",
     "origId": 3491974702989972,
     "title": "Snowfall 1956-2024",
     "version": "DashboardViewV1",
     "width": 1920
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5a. SQL queries - snowfall",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
